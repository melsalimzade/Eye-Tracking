{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8abe36d",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3635862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import timeit\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e2bee",
   "metadata": {},
   "source": [
    "Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7897948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "n_channel = 3\n",
    "mask_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485169e6",
   "metadata": {},
   "source": [
    "pathway: eye_left and eye_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4ee66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_eye_size = 11\n",
    "conv1_eye_out = 96\n",
    "pool1_eye_size = 2\n",
    "pool1_eye_stride = 2\n",
    "\n",
    "conv2_eye_size = 5\n",
    "conv2_eye_out = 256\n",
    "pool2_eye_size = 2\n",
    "pool2_eye_stride = 2\n",
    "\n",
    "conv3_eye_size = 3\n",
    "conv3_eye_out = 384\n",
    "pool3_eye_size = 2\n",
    "pool3_eye_stride = 2\n",
    "\n",
    "conv4_eye_size = 1\n",
    "conv4_eye_out = 64\n",
    "pool4_eye_size = 2\n",
    "pool4_eye_stride = 2\n",
    "\n",
    "eye_size = 2 * 2 * 2 * conv4_eye_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841763a2",
   "metadata": {},
   "source": [
    "pathway: face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc722b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onv1_face_size = 11\n",
    "conv1_face_out = 96\n",
    "pool1_face_size = 2\n",
    "pool1_face_stride = 2\n",
    "\n",
    "conv2_face_size = 5\n",
    "conv2_face_out = 256\n",
    "pool2_face_size = 2\n",
    "pool2_face_stride = 2\n",
    "\n",
    "conv3_face_size = 3\n",
    "conv3_face_out = 384\n",
    "pool3_face_size = 2\n",
    "pool3_face_stride = 2\n",
    "\n",
    "conv4_face_size = 1\n",
    "conv4_face_out = 64\n",
    "pool4_face_size = 2\n",
    "pool4_face_stride = 2\n",
    "\n",
    "face_size = 2 * 2 * conv4_face_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1af11",
   "metadata": {},
   "source": [
    "Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432c262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_eye_size = 128\n",
    "fc_face_size = 128\n",
    "fc2_face_size = 64\n",
    "fc_face_mask_size = 256\n",
    "fc2_face_mask_size = 128\n",
    "fc_size = 128\n",
    "fc2_size = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293ccf",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcdbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    npzfile = np.load(file)\n",
    "    train_eye_left = npzfile[\"train_eye_left\"]\n",
    "    train_eye_right = npzfile[\"train_eye_right\"]\n",
    "    train_face = npzfile[\"train_face\"]\n",
    "    train_face_mask = npzfile[\"train_face_mask\"]\n",
    "    train_y = npzfile[\"train_y\"]\n",
    "    val_eye_left = npzfile[\"val_eye_left\"]\n",
    "    val_eye_right = npzfile[\"val_eye_right\"]\n",
    "    val_face = npzfile[\"val_face\"]\n",
    "    val_face_mask = npzfile[\"val_face_mask\"]\n",
    "    val_y = npzfile[\"val_y\"]\n",
    "    return [train_eye_left, train_eye_right, train_face, train_face_mask, train_y], [val_eye_left, val_eye_right, val_face, val_face_mask, val_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8fc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    shape = data.shape\n",
    "    data = np.reshape(data, (shape[0], -1))\n",
    "    data = data.astype('float32') / 255. # scaling\n",
    "    data = data - np.mean(data, axis=0) # normalizing\n",
    "    return np.reshape(data, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c095335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    eye_left, eye_right, face, face_mask, y = data\n",
    "    eye_left = normalize(eye_left)\n",
    "    eye_right = normalize(eye_right)\n",
    "    face = normalize(face)\n",
    "    face_mask = np.reshape(face_mask, (face_mask.shape[0], -1)).astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    return [eye_left, eye_right, face, face_mask, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d760599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data):\n",
    "    idx = np.arange(data[0].shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i][idx]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b687c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size):\n",
    "    for i in np.arange(0, data[0].shape[0], batch_size):\n",
    "        # yield a tuple of the current batched data\n",
    "        yield [each[i: i + batch_size] for each in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13a09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeTracker(object):\n",
    "    def __init__(self):\n",
    "        # tf Graph input\n",
    "        self.eye_left = tf.placeholder(tf.float32, [None, img_size, img_size, n_channel], name='eye_left')\n",
    "        self.eye_right = tf.placeholder(tf.float32, [None, img_size, img_size, n_channel], name='eye_right')\n",
    "        self.face = tf.placeholder(tf.float32, [None, img_size, img_size, n_channel], name='face')\n",
    "        self.face_mask = tf.placeholder(tf.float32, [None, mask_size * mask_size], name='face_mask')\n",
    "        self.y = tf.placeholder(tf.float32, [None, 2], name='pos')\n",
    "        # Store layers weight & bias\n",
    "        self.weights = {\n",
    "            'conv1_eye': tf.get_variable('conv1_eye_w', shape=(conv1_eye_size, conv1_eye_size, n_channel, conv1_eye_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv2_eye': tf.get_variable('conv2_eye_w', shape=(conv2_eye_size, conv2_eye_size, conv1_eye_out, conv2_eye_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv3_eye': tf.get_variable('conv3_eye_w', shape=(conv3_eye_size, conv3_eye_size, conv2_eye_out, conv3_eye_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv4_eye': tf.get_variable('conv4_eye_w', shape=(conv4_eye_size, conv4_eye_size, conv3_eye_out, conv4_eye_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv1_face': tf.get_variable('conv1_face_w', shape=(conv1_face_size, conv1_face_size, n_channel, conv1_face_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv2_face': tf.get_variable('conv2_face_w', shape=(conv2_face_size, conv2_face_size, conv1_face_out, conv2_face_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv3_face': tf.get_variable('conv3_face_w', shape=(conv3_face_size, conv3_face_size, conv2_face_out, conv3_face_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'conv4_face': tf.get_variable('conv4_face_w', shape=(conv4_face_size, conv4_face_size, conv3_face_out, conv4_face_out), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc_eye': tf.get_variable('fc_eye_w', shape=(eye_size, fc_eye_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc_face': tf.get_variable('fc_face_w', shape=(face_size, fc_face_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc2_face': tf.get_variable('fc2_face_w', shape=(fc_face_size, fc2_face_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc_face_mask': tf.get_variable('fc_face_mask_w', shape=(mask_size * mask_size, fc_face_mask_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc2_face_mask': tf.get_variable('fc2_face_mask_w', shape=(fc_face_mask_size, fc2_face_mask_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc': tf.get_variable('fc_w', shape=(fc_eye_size + fc2_face_size + fc2_face_mask_size, fc_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "            'fc2': tf.get_variable('fc2_w', shape=(fc_size, fc2_size), initializer=tf.contrib.layers.xavier_initializer())\n",
    "        }\n",
    "        self.biases = {\n",
    "            'conv1_eye': tf.Variable(tf.constant(0.1, shape=[conv1_eye_out])),\n",
    "            'conv2_eye': tf.Variable(tf.constant(0.1, shape=[conv2_eye_out])),\n",
    "            'conv3_eye': tf.Variable(tf.constant(0.1, shape=[conv3_eye_out])),\n",
    "            'conv4_eye': tf.Variable(tf.constant(0.1, shape=[conv4_eye_out])),\n",
    "            'conv1_face': tf.Variable(tf.constant(0.1, shape=[conv1_face_out])),\n",
    "            'conv2_face': tf.Variable(tf.constant(0.1, shape=[conv2_face_out])),\n",
    "            'conv3_face': tf.Variable(tf.constant(0.1, shape=[conv3_face_out])),\n",
    "            'conv4_face': tf.Variable(tf.constant(0.1, shape=[conv4_face_out])),\n",
    "            'fc_eye': tf.Variable(tf.constant(0.1, shape=[fc_eye_size])),\n",
    "            'fc_face': tf.Variable(tf.constant(0.1, shape=[fc_face_size])),\n",
    "            'fc2_face': tf.Variable(tf.constant(0.1, shape=[fc2_face_size])),\n",
    "            'fc_face_mask': tf.Variable(tf.constant(0.1, shape=[fc_face_mask_size])),\n",
    "            'fc2_face_mask': tf.Variable(tf.constant(0.1, shape=[fc2_face_mask_size])),\n",
    "            'fc': tf.Variable(tf.constant(0.1, shape=[fc_size])),\n",
    "            'fc2': tf.Variable(tf.constant(0.1, shape=[fc2_size]))\n",
    "        }\n",
    "\n",
    "        # Construct model\n",
    "        self.pred = self.itracker_nets(self.eye_left, self.eye_right, self.face, self.face_mask, self.weights, self.biases)\n",
    "\n",
    "    # Create some wrappers for simplicity\n",
    "    def conv2d(self, x, W, b, strides=1):\n",
    "        # Conv2D wrapper, with bias and relu activation\n",
    "        x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "    def maxpool2d(self, x, k, strides):\n",
    "        # MaxPool2D wrapper\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1],\n",
    "                              padding='VALID')\n",
    "\n",
    "    # Create model\n",
    "    def itracker_nets(self, eye_left, eye_right, face, face_mask, weights, biases):\n",
    "        # pathway: left eye\n",
    "        eye_left = self.conv2d(eye_left, weights['conv1_eye'], biases['conv1_eye'], strides=1)\n",
    "        eye_left = self.maxpool2d(eye_left, k=pool1_eye_size, strides=pool1_eye_stride)\n",
    "\n",
    "        eye_left = self.conv2d(eye_left, weights['conv2_eye'], biases['conv2_eye'], strides=1)\n",
    "        eye_left = self.maxpool2d(eye_left, k=pool2_eye_size, strides=pool2_eye_stride)\n",
    "\n",
    "        eye_left = self.conv2d(eye_left, weights['conv3_eye'], biases['conv3_eye'], strides=1)\n",
    "        eye_left = self.maxpool2d(eye_left, k=pool3_eye_size, strides=pool3_eye_stride)\n",
    "\n",
    "        eye_left = self.conv2d(eye_left, weights['conv4_eye'], biases['conv4_eye'], strides=1)\n",
    "        eye_left = self.maxpool2d(eye_left, k=pool4_eye_size, strides=pool4_eye_stride)\n",
    "\n",
    "        # pathway: right eye\n",
    "        eye_right = self.conv2d(eye_right, weights['conv1_eye'], biases['conv1_eye'], strides=1)\n",
    "        eye_right = self.maxpool2d(eye_right, k=pool1_eye_size, strides=pool1_eye_stride)\n",
    "\n",
    "        eye_right = self.conv2d(eye_right, weights['conv2_eye'], biases['conv2_eye'], strides=1)\n",
    "        eye_right = self.maxpool2d(eye_right, k=pool2_eye_size, strides=pool2_eye_stride)\n",
    "\n",
    "        eye_right = self.conv2d(eye_right, weights['conv3_eye'], biases['conv3_eye'], strides=1)\n",
    "        eye_right = self.maxpool2d(eye_right, k=pool3_eye_size, strides=pool3_eye_stride)\n",
    "\n",
    "        eye_right = self.conv2d(eye_right, weights['conv4_eye'], biases['conv4_eye'], strides=1)\n",
    "        eye_right = self.maxpool2d(eye_right, k=pool4_eye_size, strides=pool4_eye_stride)\n",
    "\n",
    "        # pathway: face\n",
    "        face = self.conv2d(face, weights['conv1_face'], biases['conv1_face'], strides=1)\n",
    "        face = self.maxpool2d(face, k=pool1_face_size, strides=pool1_face_stride)\n",
    "\n",
    "        face = self.conv2d(face, weights['conv2_face'], biases['conv2_face'], strides=1)\n",
    "        face = self.maxpool2d(face, k=pool2_face_size, strides=pool2_face_stride)\n",
    "\n",
    "        face = self.conv2d(face, weights['conv3_face'], biases['conv3_face'], strides=1)\n",
    "        face = self.maxpool2d(face, k=pool3_face_size, strides=pool3_face_stride)\n",
    "\n",
    "        face = self.conv2d(face, weights['conv4_face'], biases['conv4_face'], strides=1)\n",
    "        face = self.maxpool2d(face, k=pool4_face_size, strides=pool4_face_stride)\n",
    "\n",
    "        # fc layer\n",
    "        # eye\n",
    "        eye_left = tf.reshape(eye_left, [-1, int(np.prod(eye_left.get_shape()[1:]))])\n",
    "        eye_right = tf.reshape(eye_right, [-1, int(np.prod(eye_right.get_shape()[1:]))])\n",
    "        eye = tf.concat([eye_left, eye_right], 1)\n",
    "        eye = tf.nn.relu(tf.add(tf.matmul(eye, weights['fc_eye']), biases['fc_eye']))\n",
    "\n",
    "        # face\n",
    "        face = tf.reshape(face, [-1, int(np.prod(face.get_shape()[1:]))])\n",
    "        face = tf.nn.relu(tf.add(tf.matmul(face, weights['fc_face']), biases['fc_face']))\n",
    "        face = tf.nn.relu(tf.add(tf.matmul(face, weights['fc2_face']), biases['fc2_face']))\n",
    "\n",
    "        # face mask\n",
    "        face_mask = tf.nn.relu(tf.add(tf.matmul(face_mask, weights['fc_face_mask']), biases['fc_face_mask']))\n",
    "        face_mask = tf.nn.relu(tf.add(tf.matmul(face_mask, weights['fc2_face_mask']), biases['fc2_face_mask']))\n",
    "\n",
    "        # all\n",
    "        fc = tf.concat([eye, face, face_mask], 1)\n",
    "        fc = tf.nn.relu(tf.add(tf.matmul(fc, weights['fc']), biases['fc']))\n",
    "        out = tf.add(tf.matmul(fc, weights['fc2']), biases['fc2'])\n",
    "        return out\n",
    "\n",
    "    def train(self, train_data, val_data, lr=1e-3, batch_size=128, max_epoch=1000, min_delta=1e-4, patience=10, print_per_epoch=10, out_model='my_model'):\n",
    "        ckpt = os.path.split(out_model)[0]\n",
    "        if not os.path.exists(ckpt):\n",
    "            os.makedirs(ckpt)\n",
    "\n",
    "        print('Train on %s samples, validate on %s samples' % (train_data[0].shape[0], val_data[0].shape[0]))\n",
    "        # Define loss and optimizer\n",
    "        self.cost = tf.losses.mean_squared_error(self.y, self.pred)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.cost)\n",
    "\n",
    "        # Evaluate model\n",
    "        self.err = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.squared_difference(self.pred, self.y), axis=1)))\n",
    "        train_loss_history = []\n",
    "        train_err_history = []\n",
    "        val_loss_history = []\n",
    "        val_err_history = []\n",
    "        n_incr_error = 0  # nb. of consecutive increase in error\n",
    "        best_loss = np.Inf\n",
    "        n_batches = train_data[0].shape[0] / batch_size + (train_data[0].shape[0] % batch_size != 0)\n",
    "\n",
    "        # Create the collection\n",
    "        tf.get_collection(\"validation_nodes\")\n",
    "        # Add stuff to the collection.\n",
    "        tf.add_to_collection(\"validation_nodes\", self.eye_left)\n",
    "        tf.add_to_collection(\"validation_nodes\", self.eye_right)\n",
    "        tf.add_to_collection(\"validation_nodes\", self.face)\n",
    "        tf.add_to_collection(\"validation_nodes\", self.face_mask)\n",
    "        tf.add_to_collection(\"validation_nodes\", self.pred)\n",
    "        saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "        # Initializing the variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Launch the graph\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            # Keep training until reach max iterations\n",
    "            for n_epoch in range(1, max_epoch + 1):\n",
    "                n_incr_error += 1\n",
    "                train_loss = 0.\n",
    "                val_loss = 0.\n",
    "                train_err = 0.\n",
    "                val_err = 0.\n",
    "                train_data = shuffle_data(train_data)\n",
    "                for batch_train_data in next_batch(train_data, batch_size):\n",
    "                    # Run optimization op (backprop)\n",
    "                    sess.run(self.optimizer, feed_dict={self.eye_left: batch_train_data[0], \\\n",
    "                                self.eye_right: batch_train_data[1], self.face: batch_train_data[2], \\\n",
    "                                self.face_mask: batch_train_data[3], self.y: batch_train_data[4]})\n",
    "                    train_batch_loss, train_batch_err = sess.run([self.cost, self.err], feed_dict={self.eye_left: batch_train_data[0], \\\n",
    "                                self.eye_right: batch_train_data[1], self.face: batch_train_data[2], \\\n",
    "                                self.face_mask: batch_train_data[3], self.y: batch_train_data[4]})\n",
    "                    train_loss += train_batch_loss / n_batches\n",
    "                    train_err += train_batch_err / n_batches\n",
    "                val_loss, val_err = sess.run([self.cost, self.err], feed_dict={self.eye_left: val_data[0], \\\n",
    "                                self.eye_right: val_data[1], self.face: val_data[2], \\\n",
    "                                self.face_mask: val_data[3], self.y: val_data[4]})\n",
    "\n",
    "                train_loss_history.append(train_loss)\n",
    "                train_err_history.append(train_err)\n",
    "                val_loss_history.append(val_loss)\n",
    "                val_err_history.append(val_err)\n",
    "                if val_loss - min_delta < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    save_path = saver.save(sess, out_model, global_step=n_epoch)\n",
    "                    print(\"Model saved in file: %s\" % save_path)\n",
    "                    n_incr_error = 0\n",
    "\n",
    "                if n_epoch % print_per_epoch == 0:\n",
    "                    print('Epoch %s/%s, train loss: %.5f, train error: %.5f, val loss: %.5f, val error: %.5f' % \\\n",
    "                                                (n_epoch, max_epoch, train_loss, train_err, val_loss, val_err))\n",
    "\n",
    "                if n_incr_error >= patience:\n",
    "                    print('Early stopping occured. Optimization Finished!')\n",
    "                    return train_loss_history, train_err_history, val_loss_history, val_err_history\n",
    "\n",
    "            return train_loss_history, train_err_history, val_loss_history, val_err_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a1839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_validation_handles(session):\n",
    "    \"\"\" Extracts the input and predict_op handles that we use for validation.\n",
    "    Args:\n",
    "        session: The session with the loaded graph.\n",
    "    Returns:\n",
    "        validation handles.\n",
    "    \"\"\"\n",
    "    valid_nodes = tf.get_collection_ref(\"validation_nodes\")\n",
    "    if len(valid_nodes) != 5:\n",
    "        raise Exception(\"ERROR: Expected 5 items in validation_nodes, got %d.\" % len(valid_nodes))\n",
    "    return valid_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62e391d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(session, save_path):\n",
    "    \"\"\" Loads a saved TF model from a file.\n",
    "    Args:\n",
    "        session: The tf.Session to use.\n",
    "        save_path: The save path for the saved session, returned by Saver.save().\n",
    "    Returns:\n",
    "        The inputs placehoder and the prediction operation.\n",
    "    \"\"\"\n",
    "    print(\"Loading model from file '%s'...\" % save_path)\n",
    "\n",
    "    meta_file = save_path + \".meta\"\n",
    "    if not os.path.exists(meta_file):\n",
    "        raise Exception(\"ERROR: Expected .meta file '%s', but could not find it.\" % meta_file)\n",
    "\n",
    "    saver = tf.train.import_meta_graph(meta_file)\n",
    "    # It's finicky about the save path.\n",
    "    save_path = os.path.join(\"./\", save_path)\n",
    "    saver.restore(session, save_path)\n",
    "\n",
    "    # Check that we have the handles we expected.\n",
    "    return extract_validation_handles(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "306d2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(session, val_data, val_ops):\n",
    "    \"\"\" Validates the model stored in a session.\n",
    "    Args:\n",
    "        session: The session where the model is loaded.\n",
    "        val_data: The validation data to use for evaluating the model.\n",
    "        val_ops: The validation operations.\n",
    "    Returns:\n",
    "        The overall validation error for the model. \"\"\"\n",
    "    print (\"Validating model...\")\n",
    "\n",
    "    eye_left, eye_right, face, face_mask, pred = val_ops\n",
    "    val_eye_left, val_eye_right, val_face, val_face_mask, val_y = val_data\n",
    "    y = tf.placeholder(tf.float32, [None, 2], name='pos')\n",
    "    err = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.squared_difference(pred, y), axis=1)))\n",
    "    # Validate the model.\n",
    "    error = session.run(err, feed_dict={eye_left: val_eye_left, \\\n",
    "                                eye_right: val_eye_right, face: val_face, \\\n",
    "                                face_mask: val_face_mask, y: val_y})\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0ec946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, train_err, test_err, start=0, per=1, save_file='loss.png'):\n",
    "    assert len(train_err) == len(test_err)\n",
    "    idx = np.arange(start, len(train_loss), per)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    lns1 = ax1.plot(idx, train_loss[idx], 'b-', alpha=1.0, label='train loss')\n",
    "    ax1.set_xlabel('epochs')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    ax1.set_ylabel('loss', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    lns2 = ax2.plot(idx, train_err[idx], 'r-', alpha=1.0, label='train error')\n",
    "    lns3 = ax2.plot(idx, test_err[idx], 'g-', alpha=1.0, label='test error')\n",
    "    ax2.set_ylabel('error', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # added these three lines\n",
    "    lns = lns1 + lns2 + lns3\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(save_file)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f2fd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    train_data, val_data = load_data(args.input)\n",
    "\n",
    "    # train_size = 10\n",
    "    # train_data = [each[:train_size] for each in train_data]\n",
    "    # val_size = 1\n",
    "    # val_data = [each[:val_size] for each in val_data]\n",
    "    train_data = prepare_data(train_data)\n",
    "    val_data = prepare_data(val_data)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    et = EyeTracker()\n",
    "    train_loss_history, train_err_history, val_loss_history, val_err_history = et.train(train_data, val_data, \\\n",
    "                                            lr=args.learning_rate, \\\n",
    "                                            batch_size=args.batch_size, \\\n",
    "                                            max_epoch=args.max_epoch, \\\n",
    "                                            min_delta=1e-4, \\\n",
    "                                            patience=args.patience, \\\n",
    "                                            print_per_epoch=args.print_per_epoch,\n",
    "                                            out_model=args.save_model)\n",
    "\n",
    "    print('runtime: %.1fs' % (timeit.default_timer() - start))\n",
    "\n",
    "    if args.save_loss:\n",
    "        with open(args.save_loss, 'w') as outfile:\n",
    "            np.savez(outfile, train_loss_history=train_loss_history, train_err_history=train_err_history, \\\n",
    "                                    val_loss_history=val_loss_history, val_err_history=val_err_history)\n",
    "\n",
    "    if args.plot_loss:\n",
    "        plot_loss(np.array(train_loss_history), np.array(train_err_history), np.array(val_err_history), start=0, per=1, save_file=args.plot_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573acdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args):\n",
    "    _, val_data = load_data(args.input)\n",
    "\n",
    "    # val_size = 10\n",
    "    # val_data = [each[:val_size] for each in val_data]\n",
    "\n",
    "    val_data = prepare_data(val_data)\n",
    "\n",
    "    # Load and validate the network.\n",
    "    with tf.Session() as sess:\n",
    "        val_ops = load_model(sess, args.load_model)\n",
    "        error = validate_model(sess, val_data, val_ops)\n",
    "        print('Overall validation error: %f' % error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f16f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train', action='store_true', help='train flag')\n",
    "    parser.add_argument('-i', '--input', required=True, type=str, help='path to the input data')\n",
    "    parser.add_argument('-max_epoch', '--max_epoch', type=int, default=100, help='max number of iterations (default 100)')\n",
    "    parser.add_argument('-lr', '--learning_rate', type=float, default=0.002, help='learning rate (default 1e-3)')\n",
    "    parser.add_argument('-bs', '--batch_size', type=int, default=128, help='batch size (default 50)')\n",
    "    parser.add_argument('-p', '--patience', type=int, default=5, help='early stopping patience (default 10)')\n",
    "    parser.add_argument('-pp_iter', '--print_per_epoch', type=int, default=1, help='print per iteration (default 10)')\n",
    "    parser.add_argument('-sm', '--save_model', type=str, default='my_model', help='path to the output model (default my_model)')\n",
    "    parser.add_argument('-lm', '--load_model', type=str, help='path to the loaded model')\n",
    "    parser.add_argument('-pf', '--plot_filter', type=str, default='filter.png', help='plot filters')\n",
    "    parser.add_argument('-pl', '--plot_loss', type=str, default='loss.png', help='plot loss')\n",
    "    parser.add_argument('-sl', '--save_loss', type=str, default='loss.npz', help='save loss')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.train:\n",
    "        train(args)\n",
    "    else:\n",
    "        if not args.load_model:\n",
    "            raise Exception('load_model arg needed in test phase')\n",
    "        test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653157ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
